{
    "version":"0.2.0",
    "configurations": [
        {
            "name": "Python:Current File",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "justMyCode": false,
        },
        {
            "name": "Inference",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "args": [
                "--base_model=/home/chenglibin/code/project/Chinese-LLaMA-Alpaca-2/model",
                "--with_prompt",
                "--only_cpu",
            ],
            "justMyCode": false,
            "env": {"PYTHONPYTH":"/CHINESE-LLAMA-ALPACA-2"},
        },
        {
            "name": "sft",
            "type": "python",
            "request": "launch",
            "program": "src/train_bash.py",
            "console": "integratedTerminal",
            "cwd":"${workspaceFolder}",
            "env": {"PYTHONPYTH": "${workspaceFolder}", "CUDA_VISIBLE_DEVICES": "0"},
            "args": [
                "--stage sft",
                "--model_name_or_path /home/chenglibin/code/project/llm-model/chatglm2-6b",
                "--do_train True",
                "--dataset alpaca_zh",
                "--max_source_length 256",
                "--max_target_length 256",
                "--template default",
                "--finetuning_type lora",
                "--output_dir /home/chenglibin/code/project/LLaMA-Efficient-Tuning/output",
                "--overwrite_cache True",
                "--per_device_train_batch_size 1",
                "--gradient_accumulation_steps 16",
                "--lr_scheduler_type cosine",
                "--logging_steps 10",
                "--save_steps 400",
                "--learning_rate 5e-5",
                "--num_train_epochs 1",
                "--plot_loss True",
                "--fp16 True",
                "--quantization_bit 8"
            ]
        }
    ]
}